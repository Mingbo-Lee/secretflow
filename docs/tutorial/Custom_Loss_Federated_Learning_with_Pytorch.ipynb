{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于 PyTorch 的联邦学习自定义 loss function 教程\n",
    "## 引言\n",
    "### 背景\n",
    "在联邦学习中，尤其是监督学习中，我们常常需要使用损失函数监督模型的训练；通过之前的[入门教程](https://www.secretflow.org.cn/docs/secretflow/latest/zh-Hans/tutorial/Federated_Learning_with_Pytorch_backend), 我们已经展示如何通过 `secretflow.ml.nn.utils.TorchModel` 调用 `torch.nn.CrossEntropyLoss` ，依此类推，我们可以调用 [torch.nn loss function](https://pytorch.org/docs/stable/nn.html#loss-functions) 中的任意损失函数。然而，当我们需要根据自己的任务自定义损失函数时，需要怎样做呢？本教程将回答这一问题。\n",
    "### 教程提醒\n",
    "注意，本自定义 loss function 教程主要关注输入形式为$(\\hat{y},y)$的损失函数，而不讨论超出此范围的自定义损失函数。\n",
    "具体到本教程，本教程将给出如何自定义实现\n",
    "$$\n",
    "Loss(\\hat{y},y) = 0.8*CEL(\\hat{y},y) + 0.2*MSE(\\hat{y},y)\n",
    "$$\n",
    "其中，$CEL$ 表示 [cross entropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) ，$MSE$ 表示[mean squared error](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)\n",
    "\n",
    "再度提醒，本教程只是作为教程示例，展示代码的实现，而不作为实际生产应用的模型训练指导。\n",
    "\n",
    "让我们开始吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础教程\n",
    "为突出重点，简化教程，本教程将以 [使用Pytorch后端来进行联邦学习](https://www.secretflow.org.cn/docs/secretflow/latest/zh-Hans/tutorial/Federated_Learning_with_Pytorch_backend) 为基础，重点突出自定义损失函数的做法。所以，为了让代码能够顺利运行，让我们先把之前的代码复制过来。因此如果您对原教程非常熟悉，则不需要再阅读这部分代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of SecretFlow: 1.4.0.dev20231225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 02:56:32,404\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import secretflow as sf\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print('The version of SecretFlow: {}'.format(sf.__version__))\n",
    "\n",
    "# In case you have a running secretflow runtime already.\n",
    "sf.shutdown()\n",
    "\n",
    "sf.init(['alice', 'bob', 'charlie'], address='local')\n",
    "alice, bob, charlie = sf.PYU('alice'), sf.PYU('bob'), sf.PYU('charlie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 02:56:34.323341: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-29 02:56:35.136013: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-29 02:56:35.136079: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-29 02:56:35.136087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from secretflow.ml.nn.utils import BaseModule, TorchModel\n",
    "from secretflow.ml.nn.fl.utils import metric_wrapper, optim_wrapper\n",
    "from secretflow.ml.nn import FLModel\n",
    "from torchmetrics import Accuracy, Precision\n",
    "from secretflow.security.aggregation import SecureAggregator\n",
    "from secretflow.utils.simulation.datasets import load_mnist\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(BaseModule):\n",
    "    \"\"\"Small ConvNet for MNIST.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc_in_dim = 192\n",
    "        self.fc = nn.Linear(self.fc_in_dim, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, self.fc_in_dim)\n",
    "        x = self.fc(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义损失函数\n",
    "如前所述，我们将自定义损失函数：\n",
    "$$\n",
    "Loss(\\hat{y},y) = 0.8*CEL(\\hat{y},y) + 0.2*MSE(\\hat{y},y)\n",
    "$$\n",
    "其中，$CEL$ 表示 [cross entropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)，$MSE$ 表示 [mean squared error](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)\n",
    "\n",
    "为实现这一个自定义损失函数，我们需要自行编写一个继承自 [torch.nn.module](https://github.com/pytorch/pytorch/tree/main/torch/nn/modules) 的类，而且至少实现两个基础的函数：`__init__` 和 `forward`，其中:\n",
    "- `__init__` 执行该类的初始化部分代码，本教程我们对基础损失函数 `CrossEntropyLoss` 和 `MSELoss` 进行了初始化的操作\n",
    "- `forward`  执行该类的调用时的运算代码，也就是自定义损失函数的运算逻辑，此处我们对上面所提及的自定义函数进行了实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现自定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLossFunction(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return 0.8 * self.cross_entropy_loss(input, target) + 0.2 * self.mse_loss(\n",
    "            input, target\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定自定义函数\n",
    "在下面的单元格里，我们通过\n",
    "``\n",
    "loss_fn = CustomLossFunction\n",
    "``\n",
    "指定我们自定义的损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_label), (test_data, test_label) = load_mnist(\n",
    "    parts={alice: 0.4, bob: 0.6},\n",
    "    normalized_x=True,\n",
    "    categorical_y=True,\n",
    "    is_torch=True,\n",
    ")\n",
    "\n",
    "# here we use the loss function we defined above\n",
    "loss_fn = CustomLossFunction\n",
    "\n",
    "optim_fn = optim_wrapper(optim.Adam, lr=1e-2)\n",
    "model_def = TorchModel(\n",
    "    model_fn=ConvNet,\n",
    "    loss_fn=loss_fn,\n",
    "    optim_fn=optim_fn,\n",
    "    metrics=[\n",
    "        metric_wrapper(Accuracy, task=\"multiclass\", num_classes=10, average='micro'),\n",
    "        metric_wrapper(Precision, task=\"multiclass\", num_classes=10, average='micro'),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 剩余的代码\n",
    "我们将原教程的代码继续复制过来，以展现代码的顺利运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.security.aggregation.secure_aggregator._Masker'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.security.aggregation.secure_aggregator._Masker'> with party bob.\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.fl.backend.torch.strategy.fed_avg_w.PYUFedAvgW'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.fl.backend.torch.strategy.fed_avg_w.PYUFedAvgW'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "device_list = [alice, bob]\n",
    "server = charlie\n",
    "aggregator = SecureAggregator(server, [alice, bob])\n",
    "\n",
    "# spcify params\n",
    "fl_model = FLModel(\n",
    "    server=server,\n",
    "    device_list=device_list,\n",
    "    model=model_def,\n",
    "    aggregator=aggregator,\n",
    "    strategy='fed_avg_w',  # fl strategy\n",
    "    backend=\"torch\",  # backend support ['tensorflow', 'torch']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:FL Train Params: {'x': FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f5e1fed9580>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7f5e1fed90a0>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>), 'y': FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f5e1ff25fa0>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7f5e1ff25df0>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>), 'batch_size': 32, 'batch_sampling_rate': None, 'epochs': 5, 'verbose': 1, 'callbacks': None, 'validation_data': (FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f5e1fef4910>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7f5e1fef4a90>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>), FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f5e1fe88070>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7f5e1fe882e0>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>)), 'shuffle': False, 'class_weight': None, 'sample_weight': None, 'validation_freq': 1, 'aggregate_freq': 1, 'label_decoder': None, 'max_batch_size': 20000, 'prefetch_buffer_size': None, 'sampler_method': 'batch', 'random_seed': 4317, 'dp_spent_step_freq': None, 'audit_log_dir': None, 'dataset_builder': None, 'wait_steps': 100, 'self': <secretflow.ml.nn.fl.fl_model.FLModel object at 0x7f5e1ff25850>}\n",
      "\u001b[2m\u001b[36m(pid=479273)\u001b[0m 2023-12-29 02:56:42.561450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(pid=479314)\u001b[0m 2023-12-29 02:56:42.738644: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(pid=479273)\u001b[0m 2023-12-29 02:56:43.359462: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(pid=479273)\u001b[0m 2023-12-29 02:56:43.359539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(pid=479273)\u001b[0m 2023-12-29 02:56:43.359549: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(pid=479314)\u001b[0m 2023-12-29 02:56:43.497417: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(pid=479314)\u001b[0m 2023-12-29 02:56:43.497489: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(pid=479314)\u001b[0m 2023-12-29 02:56:43.497498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Train Processing: :   0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: : 100%|█████████▉| 749/750 [00:24<00:00, 21.94it/s]/opt/anaconda3/envs/limingbo_secretflow/lib/python3.8/site-packages/secretflow/ml/nn/metrics.py:59: UserWarning: Please pay attention to local metrics, global only do naive aggregation.\n",
      "  warnings.warn(\n",
      "2023-12-29 02:57:12.484149: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-29 02:57:12.484223: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-29 02:57:12.484273: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-29 02:57:12.484314: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-29 02:57:12.485395: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /content/conda-env/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-12-29 02:57:12.485452: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Train Processing: : 100%|█████████▉| 749/750 [00:29<00:00, 25.25it/s, {'multiclassaccuracy': 0.01210625, 'multiclassprecision': 0.01210625, 'val_multiclassaccuracy': 0.025095833, 'val_multiclassprecision': 0.025095833}]\n",
      "Train Processing: :   0%|          | 3/750 [00:00<00:27, 27.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "\u001b[2m\u001b[36m(PYUFedAvgW pid=479273)\u001b[0m {'train-loss': 38.253143310546875, 'train_multiclassaccuracy': tensor(0.0122), 'train_multiclassprecision': tensor(0.0122), 'val_eval_multiclassaccuracy': tensor(0.0206), 'val_eval_multiclassprecision': tensor(0.0206)}\n",
      "\u001b[2m\u001b[36m(PYUFedAvgW pid=479314)\u001b[0m {'train-loss': 58.460208892822266, 'train_multiclassaccuracy': tensor(0.0120), 'train_multiclassprecision': tensor(0.0120), 'val_eval_multiclassaccuracy': tensor(0.0296), 'val_eval_multiclassprecision': tensor(0.0296)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: : 100%|█████████▉| 749/750 [00:33<00:00, 22.47it/s, {'multiclassaccuracy': 0.031749304, 'multiclassprecision': 0.031749304, 'val_multiclassaccuracy': 0.03495, 'val_multiclassprecision': 0.03495}]\n",
      "Train Processing: :   0%|          | 3/750 [00:00<00:27, 26.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "\u001b[2m\u001b[36m(PYUFedAvgW pid=479273)\u001b[0m {'train-loss': 38.20553970336914, 'train_multiclassaccuracy': tensor(0.0319), 'train_multiclassprecision': tensor(0.0319), 'val_eval_multiclassaccuracy': tensor(0.0307), 'val_eval_multiclassprecision': tensor(0.0307)}\n",
      "\u001b[2m\u001b[36m(PYUFedAvgW pid=479314)\u001b[0m {'train-loss': 58.438533782958984, 'train_multiclassaccuracy': tensor(0.0316), 'train_multiclassprecision': tensor(0.0316), 'val_eval_multiclassaccuracy': tensor(0.0392), 'val_eval_multiclassprecision': tensor(0.0392)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: : 100%|█████████▉| 749/750 [00:36<00:00, 20.28it/s, {'multiclassaccuracy': 0.038556945, 'multiclassprecision': 0.038556945, 'val_multiclassaccuracy': 0.0396, 'val_multiclassprecision': 0.0396}]\n",
      "Train Processing: :   1%|          | 4/750 [00:00<00:21, 34.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "\u001b[2m\u001b[36m(PYUFedAvgW pid=479273)\u001b[0m {'train-loss': 38.216060638427734, 'train_multiclassaccuracy': tensor(0.0387), 'train_multiclassprecision': tensor(0.0387), 'val_eval_multiclassaccuracy': tensor(0.0353), 'val_eval_multiclassprecision': tensor(0.0353)}\n",
      "\u001b[2m\u001b[36m(PYUFedAvgW pid=479314)\u001b[0m {'train-loss': 59.388458251953125, 'train_multiclassaccuracy': tensor(0.0384), 'train_multiclassprecision': tensor(0.0384), 'val_eval_multiclassaccuracy': tensor(0.0439), 'val_eval_multiclassprecision': tensor(0.0439)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: : 100%|█████████▉| 749/750 [00:42<00:00, 17.48it/s, {'multiclassaccuracy': 0.04316111, 'multiclassprecision': 0.04316111, 'val_multiclassaccuracy': 0.04484167, 'val_multiclassprecision': 0.04484167}]\n",
      "Train Processing: :   0%|          | 3/750 [00:00<00:25, 29.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "\u001b[2m\u001b[36m(PYUFedAvgW pid=479273)\u001b[0m {'train-loss': 38.23821258544922, 'train_multiclassaccuracy': tensor(0.0430), 'train_multiclassprecision': tensor(0.0430), 'val_eval_multiclassaccuracy': tensor(0.0397), 'val_eval_multiclassprecision': tensor(0.0397)}\n",
      "\u001b[2m\u001b[36m(PYUFedAvgW pid=479314)\u001b[0m {'train-loss': 57.66978454589844, 'train_multiclassaccuracy': tensor(0.0434), 'train_multiclassprecision': tensor(0.0434), 'val_eval_multiclassaccuracy': tensor(0.0500), 'val_eval_multiclassprecision': tensor(0.0500)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: : 100%|█████████▉| 749/750 [00:45<00:00, 16.36it/s, {'multiclassaccuracy': 0.04427014, 'multiclassprecision': 0.04427014, 'val_multiclassaccuracy': 0.045062497, 'val_multiclassprecision': 0.045062497}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PYUFedAvgW pid=479273)\u001b[0m {'train-loss': 38.21043014526367, 'train_multiclassaccuracy': tensor(0.0442), 'train_multiclassprecision': tensor(0.0442), 'val_eval_multiclassaccuracy': tensor(0.0402), 'val_eval_multiclassprecision': tensor(0.0402)}\n",
      "\u001b[2m\u001b[36m(PYUFedAvgW pid=479314)\u001b[0m {'train-loss': 57.23878860473633, 'train_multiclassaccuracy': tensor(0.0443), 'train_multiclassprecision': tensor(0.0443), 'val_eval_multiclassaccuracy': tensor(0.0499), 'val_eval_multiclassprecision': tensor(0.0499)}\n"
     ]
    }
   ],
   "source": [
    "history = fl_model.fit(\n",
    "    train_data,\n",
    "    train_label,\n",
    "    validation_data=(test_data, test_label),\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    aggregate_freq=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小节\n",
    "通过本教程，我们将学会如何基于 PyTorch 在SecretFlow 中自定义实现输入形式为 $(\\hat{y},y)$ 的损失函数。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "multi-task-learning-example-pytorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
